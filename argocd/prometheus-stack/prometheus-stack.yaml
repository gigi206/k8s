# Add inside spec.template.metadata.annotations
# prometheus.io/scrape: "true"
# prometheus.io/port: 8080
# prometheus.io/path: /metrics
# prometheus.io/scheme: http

apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: prometheus-stack
  namespace: argo-cd
spec:
  destination:
    namespace: prometheus-stack
    name: in-cluster
    # server: 'https://kubernetes.default.svc'
  source:
    chart: kube-prometheus-stack
    repoURL: 'https://prometheus-community.github.io/helm-charts'
    targetRevision: 43.2.1
    helm:
      parameters:
        ### grafana ###
        - name: grafana.ingress.enabled
          value: 'true'
        - name: grafana.ingress.hosts[0]
          value: grafana.gigix
        - name: grafana.ingress.annotations.cert-manager\.io/cluster-issuer
          value: selfsigned-cluster-issuer
        - name: grafana.ingress.tls[0].secretName
          value: grafana-cert-tls
        - name: grafana.ingress.tls[0].hosts[0]
          value: grafana.gigix
        # - name: >-
        #     grafana.service.annotations.external-dns\.alpha\.kubernetes\.io/hostname
        #   value: grafana.gigix
        - name: grafana.adminPassword
          value: prom-operator
        - name: grafana.grafana.\ini.analytics.check_for_updates
          value: 'false'
        - name: grafana.readinessProbe.timeoutSeconds
          value: '5'
        # - name: grafana.service.type
        #   value: LoadBalancer
        ### prometheus ###
        - name: prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.storageClassName
          value: longhorn
        - name: prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.accessModes[0]
          value: ReadWriteOnce
        - name: prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage
          value: 5Gi
        - name: prometheus.ingress.enabled
          value: 'true'
        - name: prometheus.ingress.hosts[0]
          value: prometheus.gigix
        - name: prometheus.ingress.tls[0].secretName
          value: prometheus-cert-tls
        - name: prometheus.ingress.tls[0].hosts[0]
          value: prometheus.gigix
        # - name: >-
        #     prometheus.service.annotations.external-dns\.alpha\.kubernetes\.io/hostname
        #   value: prometheus.gigix
        - name: prometheus.ingress.annotations.cert-manager\.io/cluster-issuer
          value: selfsigned-cluster-issuer
        # - name: server.service.type
        #   value: LoadBalancer
        ### alertmanager ###
        - name: alertmanager.ingress.enabled
          value: 'true'
        - name: alertmanager.ingress.hosts[0]
          value: alertmanager.gigix
        - name: alertmanager.ingress.tls[0].secretName
          value: alertmanager-cert-tls
        - name: alertmanager.ingress.tls[0].hosts[0]
          value: alertmanager.gigix
        - name: alertmanager.ingress.annotations.cert-manager\.io/cluster-issuer
          value: selfsigned-cluster-issuer
        # - name: >-
        #     alertmanager.service.annotations.external-dns\.alpha\.kubernetes\.io/hostname
        #   value: alertmanager.gigix
        # - name: alertmanager.service.type
        #   value: LoadBalancer
        ### pushgateway ###
        # - name: pushgateway.ingress.enabled
        #   value: 'true'
        # - name: pushgateway.ingress.hosts[0]
        #   value: pushgateway.gigix
        # - name: pushgateway.ingress.annotations.cert-manager\.io/cluster-issuer
        #   value: selfsigned-cluster-issuer
        # - name: >-
        #     pushgateway.service.annotations.external-dns\.alpha\.kubernetes\.io/hostname
        #   value: pushgateway.gigix
        # - name: pushgateway.service.type
        #   value: LoadBalancer
        ### kubeControllerManager ###
        # - name: kubeControllerManager.endpoints[0]
        #   value: 192.168.122.122.x
        # - name: kubeControllerManager.service.port
        #   value: 10257
        # - name: kubeControllerManager.service.targetPort
        #   value: 10257
        # - name: kubeControllerManager.serviceMonitor.https
        #   value: "true"
        # - name: kubeControllerManager.serviceMonitor.insecureSkipVerify
        #   value: "true"
        ### kubeScheduler ###
        # - name: kubeScheduler.endpoints[0]
        #   value: 192.168.122.122.x
        # - name: kubeScheduler.service.port
        #   value: 10259
        # - name: kubeScheduler.service.targetPort
        #   value: 10259
        # - name: kubeScheduler.serviceMonitor.https
        #   value: "true"
        # - name: kubeScheduler.serviceMonitor.insecureSkipVerify
        #   value: "true"
        ### kubeProxy ###
        # - name: kubeProxy.endpoints[0]
        #   value: 192.168.122.122.x
        # - name: kubeProxy.service.port
        #   value: 10249
        # - name: kubeProxy.service.targetPort
        #   value: 10249

        ########################
        #                      #
        # Linkerd integration  #
        #                      #
        ########################

        # #### Linkerd Grafana ###
        # # Cf https://linkerd.io/2.11/tasks/grafana/
        # - name: grafana.grafana.\ini.server.root_url
        #   value: '%(protocol)s://%(domain)s:/grafana/'
        # - name: grafana.grafana.\ini.panels.disable_sanitize_html
        #   value: 'true'
        # # Dashboard
        # # All these charts are hosted at https://grafana.com/grafana/dashboards/{id}
        # # top-line
        # - name: grafana.dashboards.default.top-line.gnetId
        #   value: '15474'
        # - name: grafana.dashboards.default.top-line.revision
        #   value: '3'
        # - name: grafana.dashboards.default.top-line.datasource
        #   value: Prometheus
        # # health
        # - name: grafana.dashboards.default.health.gnetId
        #   value: '15486'
        # - name: grafana.dashboards.default.health.revision
        #   value: '2'
        # - name: grafana.dashboards.default.health.datasource
        #   value: Prometheus
        # # kubernetes
        # - name: grafana.dashboards.default.kubernetes.gnetId
        #   value: '15479'
        # - name: grafana.dashboards.default.kubernetes.revision
        #   value: '2'
        # - name: grafana.dashboards.default.kubernetes.datasource
        #   value: Prometheus
        # # namespace
        # - name: grafana.dashboards.default.namespace.gnetId
        #   value: '15478'
        # - name: grafana.dashboards.default.namespace.revision
        #   value: '2'
        # - name: grafana.dashboards.default.namespace.datasource
        #   value: Prometheus
        # # deployment
        # - name: grafana.dashboards.default.deployment.gnetId
        #   value: '15475'
        # - name: grafana.dashboards.default.deployment.revision
        #   value: '5'
        # - name: grafana.dashboards.default.deployment.datasource
        #   value: Prometheus
        # # pod
        # - name: grafana.dashboards.default.pod.gnetId
        #   value: '15477'
        # - name: grafana.dashboards.default.pod.revision
        #   value: '2'
        # - name: grafana.dashboards.default.pod.datasource
        #   value: Prometheus
        # # service
        # - name: grafana.dashboards.default.service.gnetId
        #   value: '15480'
        # - name: grafana.dashboards.default.service.revision
        #   value: '2'
        # - name: grafana.dashboards.default.service.datasource
        #   value: Prometheus
        # # route
        # - name: grafana.dashboards.default.route.gnetId
        #   value: '15481'
        # - name: grafana.dashboards.default.route.revision
        #   value: '2'
        # - name: grafana.dashboards.default.route.datasource
        #   value: Prometheus
        # # authority
        # - name: grafana.dashboards.default.authority.gnetId
        #   value: '15482'
        # - name: grafana.dashboards.default.authority.revision
        #   value: '2'
        # - name: grafana.dashboards.default.authority.datasource
        #   value: Prometheus
        # # cronjob
        # - name: grafana.dashboards.default.cronjob.gnetId
        #   value: '15483'
        # - name: grafana.dashboards.default.cronjob.revision
        #   value: '2'
        # - name: grafana.dashboards.default.cronjob.datasource
        #   value: Prometheus
        # # job
        # - name: grafana.dashboards.default.job.gnetId
        #   value: '15487'
        # - name: grafana.dashboards.default.job.revision
        #   value: '2'
        # - name: grafana.dashboards.default.job.datasource
        #   value: Prometheus
        # # daemonset
        # - name: grafana.dashboards.default.daemonset.gnetId
        #   value: '15484'
        # - name: grafana.dashboards.default.daemonset.revision
        #   value: '2'
        # - name: grafana.dashboards.default.daemonset.datasource
        #   value: Prometheus
        # # replicaset
        # - name: grafana.dashboards.default.replicaset.gnetId
        #   value: '15491'
        # - name: grafana.dashboards.default.replicaset.revision
        #   value: '2'
        # - name: grafana.dashboards.default.replicaset.datasource
        #   value: Prometheus
        # # statefulset
        # - name: grafana.dashboards.default.statefulset.gnetId
        #   value: '15493'
        # - name: grafana.dashboards.default.statefulset.revision
        #   value: '2'
        # - name: grafana.dashboards.default.statefulset.datasource
        #   value: Prometheus
        # # replicationcontroller
        # - name: grafana.dashboards.default.replicationcontroller.gnetId
        #   value: '15492'
        # - name: grafana.dashboards.default.replicationcontroller.revision
        #   value: '2'
        # - name: grafana.dashboards.default.replicationcontroller.datasource
        #   value: Prometheus
        # # prometheus
        # - name: grafana.dashboards.default.prometheus.gnetId
        #   value: '15489'
        # - name: grafana.dashboards.default.prometheus.revision
        #   value: '2'
        # - name: grafana.dashboards.default.prometheus.datasource
        #   value: Prometheus
        # # prometheus-benchmark
        # - name: grafana.dashboards.default.prometheus-benchmark.gnetId
        #   value: '15490'
        # - name: grafana.dashboards.default.prometheus-benchmark.revision
        #   value: '2'
        # - name: grafana.dashboards.default.prometheus-benchmark.datasource
        #   value: Prometheus
        # # multicluster
        # - name: grafana.dashboards.default.multicluster.gnetId
        #   value: '15488'
        # - name: grafana.dashboards.default.multicluster.revision
        #   value: '2'
        # - name: grafana.dashboards.default.multicluster.datasource
        #   value: Prometheus

        # #### Linkerd Prometheus ###
        # # Cf https://linkerd.io/2.11/tasks/external-prometheus/
        # # linkerd-controller
        # - name: prometheus.prometheusSpec.additionalScrapeConfigs
        #   value: |
        #     - job_name: linkerd-controller
        #       honor_timestamps: true
        #       scrape_interval: 10s
        #       scrape_timeout: 10s
        #       metrics_path: /metrics
        #       scheme: http
        #       kubernetes_sd_configs:
        #       - role: pod
        #         namespaces:
        #           names:
        #           - linkerd
        #           - linkerd-viz
        #       relabel_configs:
        #       - source_labels: [__meta_kubernetes_pod_container_port_name]
        #         separator: ;
        #         regex: admin-http
        #         replacement: $1
        #         action: keep
        #       - source_labels: [__meta_kubernetes_pod_container_name]
        #         separator: ;
        #         regex: (.*)
        #         target_label: component
        #         replacement: $1
        #         action: replace
        #     - job_name: linkerd-service-mirror
        #       honor_timestamps: true
        #       scrape_interval: 10s
        #       scrape_timeout: 10s
        #       metrics_path: /metrics
        #       scheme: http
        #       kubernetes_sd_configs:
        #       - role: pod
        #       relabel_configs:
        #       - source_labels: [__meta_kubernetes_pod_label_linkerd_io_control_plane_component, __meta_kubernetes_pod_container_port_name]
        #         separator: ;
        #         regex: linkerd-service-mirror;admin-http$
        #         replacement: $1
        #         action: keep
        #       - source_labels: [__meta_kubernetes_pod_container_name]
        #         separator: ;
        #         regex: (.*)
        #         target_label: component
        #         replacement: $1
        #         action: replace
        #     - job_name: linkerd-proxy
        #       honor_timestamps: true
        #       scrape_interval: 10s
        #       scrape_timeout: 10s
        #       metrics_path: /metrics
        #       scheme: http
        #       kubernetes_sd_configs:
        #       - role: pod
        #       relabel_configs:
        #       - source_labels: [__meta_kubernetes_pod_container_name, __meta_kubernetes_pod_container_port_name, __meta_kubernetes_pod_label_linkerd_io_control_plane_ns]
        #         separator: ;
        #         regex: ^linkerd-proxy;linkerd-admin;linkerd$
        #         replacement: $1
        #         action: keep
        #       - source_labels: [__meta_kubernetes_namespace]
        #         separator: ;
        #         regex: (.*)
        #         target_label: namespace
        #         replacement: $1
        #         action: replace
        #       - source_labels: [__meta_kubernetes_pod_name]
        #         separator: ;
        #         regex: (.*)
        #         target_label: pod
        #         replacement: $1
        #         action: replace
        #       - source_labels: [__meta_kubernetes_pod_label_linkerd_io_proxy_job]
        #         separator: ;
        #         regex: (.*)
        #         target_label: k8s_job
        #         replacement: $1
        #         action: replace
        #       - separator: ;
        #         regex: __meta_kubernetes_pod_label_linkerd_io_proxy_job
        #         # replacement: $1
        #         action: labeldrop
        #       - separator: ;
        #         regex: __meta_kubernetes_pod_label_linkerd_io_proxy_(.+)
        #         replacement: $1
        #         action: labelmap
        #       - separator: ;
        #         regex: __meta_kubernetes_pod_label_linkerd_io_proxy_(.+)
        #         # replacement: $1
        #         action: labeldrop
        #       - separator: ;
        #         regex: __meta_kubernetes_pod_label_linkerd_io_(.+)
        #         replacement: $1
        #         action: labelmap
        #       - separator: ;
        #         regex: __meta_kubernetes_pod_label_(.+)
        #         replacement: __tmp_pod_label_$1
        #         action: labelmap
        #       - separator: ;
        #         regex: __tmp_pod_label_linkerd_io_(.+)
        #         replacement: __tmp_pod_label_$1
        #         action: labelmap
        #       - separator: ;
        #         regex: __tmp_pod_label_linkerd_io_(.+)
        #         # replacement: $1
        #         action: labeldrop
        #       - separator: ;
        #         regex: __tmp_pod_label_(.+)
        #         replacement: $1
        #         action: labelmap
  project: default
  syncPolicy:
    syncOptions:
      # - Replace=true # use as workaroud (not recommended) => https://blog.ediri.io/kube-prometheus-stack-and-argocd-23-how-to-remove-a-workaround
      - CreateNamespace=true
      - PruneLast=true
