# https://github.com/isItObservable/Otel-Collector-Observek8s
# https://www.youtube.com/watch?v=NTsK_0t9eRU&list=PL6VBQyIvTlRjAMeeZN5yfD07X8DdYonnI&index=11

# https://github.com/antonmedv/expr/blob/master/docs/Language-Definition.md

apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: otelcontribcol
  name: otelcontribcol
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
rules:
  - apiGroups:
      - ""
    resources:
      - events
      - namespaces
      - namespaces/status
      - nodes
      - nodes/spec
      - nodes/stats
      - nodes/proxy
      - pods
      - pods/status
      - replicationcontrollers
      - replicationcontrollers/status
      - resourcequotas
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - apps
    resources:
      - daemonsets
      - deployments
      - replicasets
      - statefulsets
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - extensions
    resources:
      - daemonsets
      - deployments
      - replicasets
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - batch
    resources:
      - jobs
      - cronjobs
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - autoscaling
    resources:
      - horizontalpodautoscalers
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otelcontribcol
  labels:
    app: otelcontribcol
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otelcontribcol
subjects:
  - kind: ServiceAccount
    name: otelcontribcol
    namespace: default
---
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: simplest
  namespace: opentelemetry-collector
spec:
  # https://hub.docker.com/r/otel/opentelemetry-collector-contrib/tags
  # image: otel/opentelemetry-collector-contrib-dev:latest
  # image: otel/opentelemetry-collector-contrib:0.84.0
  # This image contains journalctl binary to parse /var/log/journal files
  image: gigi206/opentelemetry-collector-contrib:0.84.0
  imagePullPolicy: Always
  serviceAccount: otelcontribcol
  mode: daemonset
  hostNetwork: true
  # resources:
  #   limits:
  #   requests:
  volumes:
    - name: varlog
      hostPath:
        path: /var/log
    - name: rke2agent
      hostPath:
        path: /var/lib/rancher/rke2/agent/logs/
    - name: journal
      hostPath:
        path: /var/log/journal
  volumeMounts:
    - mountPath: /var/log
      name: varlog
      readOnly: true
    - mountPath: /var/lib/rancher/rke2/agent/logs/
      name: rke2agent
      readOnly: true
    - mountPath: /var/log/journal
      name: journal
      readOnly: true
  ports:
    - name: metric
      port: 9090
      targetPort: 9090
      protocol: TCP
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # - name: HOST_IP
    #   valueFrom:
    #     fieldRef:
    #       fieldPath: status.hostIP
    - name: K8S_CLUSTER_NAME
      value: K8S_GIGIX_DEMO
  config: |
    # https://github.com/open-telemetry/opentelemetry-collector/tree/main/receiver
    # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver
    receivers:
      otlp: # https://github.com/open-telemetry/opentelemetry-collector/tree/main/receiver/otlpreceiver
        protocols:
          grpc:
          http:
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/journaldreceiver
      journald:
        directory: /var/log/journal
        start_at: end
        # dmesg: true
        # storage: xxx
        # retry_on_failure.enabled: true
        # retry_on_failure.initial_interval: 3s
        # retry_on_failure.max_interval: 30s
        # retry_on_failure.max_elapsed_time: 60m
        # operators:
        #   - type: json_parser
        #     # parse_from: body
        #     # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/stanza/docs/types/timestamp.md
        #     timestamp:
        #       parse_from: body.SOURCE_REALTIME_TIMESTAMP
        #       layout_type: epoch
        #       layout: s
        #     # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/stanza/docs/types/severity.md
        #     severity:
        #       parse_from: body.SYSLOG_FACILITY
        #       mapping:
        #         #fatal: [0, 1, 2]
        #         fatal:
        #           min: 0
        #           max: 2
        #         error: [3]
        #         warn: [4]
        #         info: [5]
        #         debug: [6]
        #         trace: [7]
        #         #0: Emergency
        #         #1: Alert
        #         #2: Critical
        #         #3: Error
        #         #4: Warning
        #         #5: Notice
        #         #6: Informational
        #         #7: Debugging
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/filelogreceiver
      filelog:
        include:
          - /var/log/pods/*/*/*.log
        exclude:
          - /var/log/pods/*/otc-container/*.log
        # start_at: beginning
        start_at: end
        include_file_path: true
        include_file_name: false
        # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/stanza/docs/operators/README.md
        operators:
          # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/stanza/docs/operators/router.md
          # Find out which format is used by kubernetes
          - type: router
            id: get-format
            routes:
              - output: parser-containerd
                expr: 'body matches "^[^ Z]+Z"'
          # Parse CRI-Containerd format
          - type: regex_parser
            id: parser-containerd
            regex: '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) (?P<log>.*)$'
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: attributes.time
              layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            # severity:
            #   parse_from: sev
            # severity:
            #   parse_from: level
            #   mapping:
            #     error: E
            #     info: I
            # trace:
            #   trace_id:
            #     parse_from: attributes.trace_id
          # Extract metadata from file path
          - type: regex_parser
            id: extract_metadata_from_filepath
            regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<run_id>\d+)\.log$'
            parse_from: attributes["log.file.path"]
          # Rename attributes
          - type: move
            from: attributes.log
            to: body
          - type: move
            from: attributes.stream
            to: attributes["log.iostream"]
          - type: move
            from: attributes.container_name
            # to: attributes["k8s.container.name"]
            to: resource["k8s.container.name"]
          - type: move
            from: attributes.namespace
            # to: attributes["k8s.namespace.name"]
            to: resource["k8s.namespace.name"]
          - type: move
            from: attributes.pod_name
            # to: attributes["k8s.pod.name"]
            to: resource["k8s.pod.name"]
          - type: move
            from: attributes.restart_count
            # to: attributes["k8s.container.restart_count"]
            to: resource["k8s.container.restart_count"]
          - type: move
            from: attributes.uid
            # to: attributes["k8s.pod.uid"]
            to: resource["k8s.pod.uid"]
          - type: add
            field: resource["k8s.cluster.name"]
            value: '${K8S_CLUSTER_NAME}'
          - type: add
            field: resource["k8s.node.name"]
            value: '${K8S_NODE_NAME}'
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/hostmetricsreceiver
      hostmetrics:
          collection_interval: 30s
          scrapers:
            cpu:
            disk:
            load:
              cpu_average: true
            filesystem:
            memory:
            network:
            paging:
            processes:
            process:
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/k8sclusterreceiver
      k8s_cluster:
        collection_interval: 10s
        node_conditions_to_report: [Ready,MemoryPressure,DiskPressure,NetworkUnavailable,PIDPressure]
        allocatable_types_to_report:
          - cpu
          - memory
          - storage
          # - ephemeral-storage
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/k8seventsreceiver
      k8s_events:
        auth_type : serviceAccount
        # namespaces: [ns1, ns2]
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/k8sobjectsreceiver
      # k8sobjects:
      #   auth_type: serviceAccount
      #   objects:
      #     - name: pods
      #       mode: pull
      #       label_selector: environment in (production),tier in (frontend)
      #       field_selector: status.phase=Running
      #       interval: 15m
      #     - name: events
      #       mode: watch
      #       # group: events.k8s.io
      #       # namespaces: [default]
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/receivercreator
      # receiver_creator:
      #   watch_observers: [k8s_observer]
      #   # watch_observers: [k8s_observer,host_observer]
      #   receivers:
      #     kubeletstats:
      #       rule: type == "k8s.node"
      #       config:
      #         collection_interval: 10s
      #         auth_type: serviceAccount
      #         # endpoint: "`endpoint`:`kubelet_endpoint_port`"
      #         insecure_skip_verify: true
      #         extra_metadata_labels:
      #           - container.id
      #           - k8s.volume.type
      #         metric_groups:
      #           - node
      #           - pod
      #           - volume
      #           - container
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/kubeletstatsreceiver
      kubeletstats:
        collection_interval: 10s
        auth_type: serviceAccount
        # endpoint: "`endpoint`:`kubelet_endpoint_port`"
        insecure_skip_verify: true
        extra_metadata_labels:
          - container.id
          - k8s.volume.type
        metric_groups:
          - node
          - pod
          - volume
          - container
    processors:
      # https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor/batchprocessor
      batch:
        send_batch_max_size: 1000
        timeout: 30s
        send_batch_size : 800
      # https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor/memorylimiterprocessor
      memory_limiter:
         check_interval: 1s
         limit_percentage: 70
         spike_limit_percentage: 30
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/metricstransformprocessor
      # metricstransform:
      #   transforms:
      #      include: .+
      #      match_type: regexp
      #      action: update
      #      operations:
      #        - action: add_label
      #          new_label: kubernetes.cluster.id
      #          new_value: CLUSTER_ID_TO_REPLACE
      #        - action: add_label
      #          new_label: kubernetes.name
      #          new_value: CLUSTER_NAME_TO_REPLACE
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/k8sattributesprocessor
      k8sattributes:
        auth_type: serviceAccount
        passthrough: false
        filter:
          node_from_env_var: K8S_NODE_NAME
        pod_association:
          - sources:
            - from: resource_attribute
              name: k8s.pod.uid
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
            - k8s.replicaset.name
            - k8s.replicaset.uid
            - k8s.daemonset.name
            - k8s.daemonset.uid
            - k8s.job.name
            - k8s.job.uid
            - k8s.cronjob.name
            - k8s.statefulset.name
            - k8s.statefulset.uid
            - k8s.container.name
            - container.image.name
            - container.image.tag
            - container.id
          labels:
            - tag_name: kube_app_name
              key: app.kubernetes.io/name
              from: pod
            - tag_name: kube_app_instance
              key: app.kubernetes.io/instance
              from: pod
            - tag_name: kube_app_version
              key: app.kubernetes.io/version
              from: pod
            - tag_name: kube_app_component
              key: app.kubernetes.io/component
              from: pod
            - tag_name: kube_app_part_of
              key: app.kubernetes.io/part-of
              from: pod
            - tag_name: kube_app_managed_by
              key: app.kubernetes.io/managed-by
              from: pod
          #annotations:
          #  - tag_name: monitoring
          #    key: monitoring
          #    from: pod
        # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/resourceprocessor
      resource/k8s_events:
        attributes:
          # Parse from k8s_events to send to Loki
          - action: insert
            key: k8s_nodename
            from_attribute: k8s.node.name
          # - action: insert
          #   key: k8s_object_kind
          #   from_attribute: k8s.object.kind
          # - action: insert
          #   key: k8s_object_name
          #   from_attribute: k8s.object.name
          # - action: insert
          #   key: k8s_object_fieldpath
          #   from_attribute: k8s.object.fieldpath
          - action: insert
            key: loki.resource.labels
            value: k8s_nodename
            # value: k8s_nodename, k8s_object_kind, k8s_object_name, k8s_object_fieldpath
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/attributesprocessor
      attributes/k8s_events:
        actions:
          # Parse from k8s_events to send to Loki
          - action: insert
            key: source
            value: k8s
          - action: insert
            key: type
            value: k8s_events
          - action: insert
            key: k8s_namespace
            from_attribute: k8s.namespace.name
          # - action: insert
          #   key: k8s_event_reason
          #   from_attribute: k8s.event.reason
          # - action: insert
          #   key: k8s_event_action
          #   from_attribute: k8s.event.action
          - action: insert
            key: loki.attribute.labels
            value: source, type, k8s_namespace
            # value: source, type, k8s_namespace, k8s_event_reason, k8s_event_action
      attributes/journal:
        actions:
          # Parse from journald
          - action: insert
            key: type
            value: journald
          - action: insert
            key: source
            value: systemd
          - action: insert
            key: loki.attribute.labels
            value: type, source
      # resourcedetection:
      #   detectors: [env, system]
    exporters:
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/prometheusexporter
      prometheus:
        endpoint: "0.0.0.0:9090"
        metric_expiration: 180m
        resource_to_telemetry_conversion:
          enabled: true
      # https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/loggingexporter/README.md
      logging:
        verbosity: detailed
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/lokiexporter
      loki:
        endpoint: http://loki-stack.loki-stack.svc.cluster.local:3100/loki/api/v1/push
        # tls:
        #   insecure: true
        #   ca_file: /var/lib/mycert.pem
        #   cert_file: certfile
        #   key_file: keyfile
        # timeout: 10s
        # read_buffer_size: 123
        # write_buffer_size: 345
        # sending_queue:
        #   enabled: true
        #   num_consumers: 2
        #   queue_size: 10
        retry_on_failure:
          enabled: true
          initial_interval: 10s
          max_interval: 60s
          max_elapsed_time: 60m
        # headers:
        #   "X-Custom-Header": "loki_rocks"
        default_labels_enabled:
          exporter: false
          job: false
          # instance: false
          # level: false
    extensions:
      # https://github.com/open-telemetry/opentelemetry-collector/tree/main/extension/ballastextension
      memory_ballast:
        size_in_percentage: 20
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/extension/observer/README.md
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/extension/observer/k8sobserver/README.md
      k8s_observer:
        auth_type: serviceAccount
        node: ${K8S_NODE_NAME}
        observe_pods: true
        observe_nodes: true
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/extension/observer/hostobserver/README.md
      # host_observer:
      #   refresh_interval: 10s
    service:
      # telemetry:
      #   logs:
      #     level: DEBUG
      extensions: [k8s_observer,memory_ballast]
      pipelines:
        logs:
          receivers: [filelog]
          processors: [memory_limiter,k8sattributes,batch]
          # exporters: [loki,logging]
          exporters: [logging]
        logs/journald:
          receivers: [journald]
          processors: [memory_limiter,attributes/journal,batch]
          # exporters: [logging,loki]
          exporters: [logging]
        logs/k8s_events:
          receivers: [k8s_events]
          processors: [memory_limiter,attributes/k8s_events,resource/k8s_events,batch]
          # exporters: [loki,logging]
          exporters: [logging]
        # journald receiver require to build a custom container image
        # - https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder
        # - https://opentelemetry.io/docs/collector/custom-collector/
        # - https://github.com/open-telemetry/opentelemetry-collector-releases/releases/latest
        # - https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/cmd/otelcontribcol/Dockerfile
        # logs/journald:
        #  receivers: [journald]
        #  processors: [memory_limiter,batch]
        #  exporters: [logging,loki]
        metrics:
          receivers: [k8s_cluster,kubeletstats]
          processors: [memory_limiter,k8sattributes,batch]
          # processors: [memory_limiter,resourcedetection,metricstransform,k8sattributes,batch]
          # exporters: [prometheus,loki]
          exporters: [logging]