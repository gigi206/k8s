---
# =============================================================================
# Velero ApplicationSet (Kubernetes Backup & Restore)
# =============================================================================
# Deploys Velero for cluster backup and disaster recovery.
# Uses S3 storage via Rook-Ceph ObjectStore for backup metadata.
# Volume backups use CSI snapshots (Ceph RBD).
# BackupStorageLocation is created by a PreSync Job that reads OBC credentials.
# Docs: https://velero.io/docs/
# =============================================================================

apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: velero
  namespace: argo-cd
  annotations:
spec:
  goTemplate: true
  goTemplateOptions: ["missingkey=error"]

  generators:
    - merge:
        mergeKeys:
          - environment
        generators:
          # Global config
          - git:
              repoURL: https://github.com/gigi206/k8s
              revision: 'HEAD'
              files:
                - path: deploy/argocd/config/config.yaml

          # App-specific config
          - git:
              repoURL: https://github.com/gigi206/k8s
              revision: 'HEAD'
              files:
                - path: deploy/argocd/apps/velero/config/*.yaml

  template:
    metadata:
      name: velero
      namespace: argo-cd
      annotations:
    spec:
      project: default

      source:
        repoURL: https://vmware-tanzu.github.io/helm-charts
        targetRevision: '{{ .velero.version }}'
        chart: velero

      destination:
        server: https://kubernetes.default.svc
        namespace: '{{ .velero.namespace }}'

      syncPolicy:
        retry:
          limit: 10
          backoff:
            duration: 10s
            factor: 2
            maxDuration: 10m

  templatePatch: |
    spec:
      syncPolicy:
        syncOptions:
        {{- range .syncPolicy.syncOptions }}
          - {{ . }}
        {{- end }}
      {{- if .syncPolicy.automated.enabled }}
        automated:
          prune: {{ .syncPolicy.automated.prune }}
          selfHeal: {{ .syncPolicy.automated.selfHeal }}
      {{- end }}

      ignoreDifferences:
        - group: external-secrets.io
          kind: ExternalSecret
          jqPathExpressions:
            - .spec.data[].remoteRef.conversionStrategy
            - .spec.data[].remoteRef.decodingStrategy
            - .spec.data[].remoteRef.metadataPolicy

      sources:
        # Source: Namespace with PSA labels
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "namespace.yaml"

        {{- if and .features.s3.enabled (eq .features.s3.provider "rook") }}
        # Source: PreSync check - wait for Ceph storage + OBC CRD readiness
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "ceph-storage-presync-check.yaml"

        # Source: PreSync Job to create OBC + Velero S3 credentials + BSL
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "velero-s3-credentials.yaml"

        # Source: VolumeSnapshotClass for Ceph RBD CSI snapshots
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "volumesnapshotclass.yaml"
        {{- end }}

        {{- if .features.kyverno.enabled }}
        # Source: Kyverno PolicyException (allows SA token mount for K8s API access)
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "kyverno-policy-exception.yaml"
        {{- end }}

        {{- if .features.networkPolicy.defaultDenyPodIngress.enabled }}
          {{- if eq .cni.primary "cilium" }}
        # Source: Cilium policy for internal Velero traffic
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "cilium-ingress-policy.yaml"
          {{- else if eq .cni.primary "calico" }}
        # Source: Calico policy for internal Velero traffic
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "calico-ingress-policy.yaml"
          {{- end }}
        {{- end }}

        # Source: Velero Helm Chart
        - repoURL: https://vmware-tanzu.github.io/helm-charts
          targetRevision: '{{ .velero.version }}'
          chart: velero
          helm:
            releaseName: velero
            valuesObject:
              # Init containers: AWS plugin for S3
              initContainers:
                - name: velero-plugin-for-aws
                  image: 'velero/velero-plugin-for-aws:{{ .velero.pluginAws.version }}'
                  imagePullPolicy: IfNotPresent
                  volumeMounts:
                    - mountPath: /target
                      name: plugins

              # Resources
              resources:
                requests:
                  cpu: '{{ .velero.resources.requests.cpu }}'
                  memory: '{{ .velero.resources.requests.memory }}'
                limits:
                  cpu: '{{ .velero.resources.limits.cpu }}'
                  memory: '{{ .velero.resources.limits.memory }}'

              # SecurityContext (PSA compatible)
              podSecurityContext:
                runAsNonRoot: true
                runAsUser: 65534
                runAsGroup: 65534
                fsGroup: 65534
                seccompProfile:
                  type: RuntimeDefault
              containerSecurityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop: ["ALL"]
                readOnlyRootFilesystem: true

              # CRDs managed by ArgoCD directly (not by Helm hook Job)
              # See README.md "Known Issues" for why upgradeCRDs is disabled
              upgradeCRDs: false

              {{- if and .features.s3.enabled (eq .features.s3.provider "rook") }}
              # Disable Helm-managed BSL (created by PreSync Job with OBC credentials)
              backupsEnabled: false
              # No Helm-managed VSL (CSI uses VolumeSnapshotClass directly)
              snapshotsEnabled: false

              # Credentials (existingSecret created by PreSync Job)
              credentials:
                useSecret: true
                existingSecret: '{{ .velero.s3.secretName }}'

              # Server configuration
              configuration:
                # Enable built-in CSI snapshot support
                features: EnableCSI
                # No server-side defaults: each backup chooses via UI/CLI
                # No VolumeSnapshotLocation needed for CSI (uses VolumeSnapshotClass directly)
                volumeSnapshotLocation: []
                # Kopia needs a writable HOME for config files (~/.config/kopia/)
                # The distroless Velero image has HOME=/nonexistent (read-only)
                # Redirect HOME to /scratch (existing emptyDir volume)
                extraEnvVars:
                  - name: HOME
                    value: /scratch
              {{- end }}

              # Node-agent (data mover: uploads CSI snapshot data to S3)
              deployNodeAgent: {{ .velero.nodeAgent.enabled }}
              {{- if .velero.nodeAgent.enabled }}
              nodeAgent:
                resources:
                  requests:
                    cpu: '{{ .velero.nodeAgent.resources.requests.cpu }}'
                    memory: '{{ .velero.nodeAgent.resources.requests.memory }}'
                  limits:
                    cpu: '{{ .velero.nodeAgent.resources.limits.cpu }}'
                    memory: '{{ .velero.nodeAgent.resources.limits.memory }}'
                podSecurityContext:
                  runAsUser: 0
              {{- end }}

              # Backup schedules
              schedules:
                daily-backup:
                  schedule: '{{ .velero.schedule.cron }}'
                  useOwnerReferencesInBackup: false
                  template:
                    ttl: '{{ .velero.schedule.ttl }}'
                    storageLocation: default

              # Metrics
              metrics:
                enabled: {{ .features.monitoring.enabled }}
                {{- if .features.monitoring.enabled }}
                serviceMonitor:
                  enabled: true
                  additionalLabels:
                    release: '{{ .features.monitoring.release }}'
                prometheusRule:
                  enabled: false
                {{- if .velero.nodeAgent.enabled }}
                nodeAgentPodMonitor:
                  enabled: true
                  additionalLabels:
                    release: '{{ .features.monitoring.release }}'
                {{- end }}
                {{- end }}

        {{- if .features.monitoring.enabled }}
        # Source: PrometheusRules for Velero monitoring
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/kustomize/monitoring
          kustomize:
            commonLabels:
              release: '{{ .features.monitoring.release }}'
              grafana_dashboard: '{{ .features.monitoring.dashboard.label }}'
            commonAnnotations:
              "{{ .features.monitoring.dashboard.folderAnnotation }}": '{{ .features.monitoring.dashboard.baseFolder }}/{{ .dashboard.folder }}'
        {{- end }}

        {{- if .velero.dashboard.enabled }}
        {{- if and .features.sso.enabled (eq .features.sso.provider "keycloak") }}
        # Source: SOPS-encrypted secrets (OIDC client secret for velero-ui)
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/secrets/{{ .environment }}

        # Source: SSO - Keycloak OIDC client creation + CA cert
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/kustomize/sso
          kustomize:
            images:
              - 'curlimages/curl={{ .images.curl.repository }}:{{ .images.curl.tag }}'
            patches:
              - target:
                  kind: Job
                  name: velero-ui-keycloak-oidc-client
                patch: |
                  - op: replace
                    path: /spec/template/spec/containers/0/env/0/value
                    value: {{ .common.domain }}
        {{- end }}

        {{- if .features.gatewayAPI.enabled }}
        {{- if .features.gatewayAPI.httpRoute.enabled }}
        # Source: HTTPRoute for Velero UI (native OIDC - no oauth2-proxy needed)
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/kustomize/httproute
          kustomize:
            patches:
              - target:
                  kind: HTTPRoute
                  name: velero-ui
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: velero.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: ReferenceGrant
                  name: gateway-velero-ui-tls
                patch: |
                  - op: replace
                    path: /spec/from/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
        {{- else if eq .features.gatewayAPI.controller.provider "apisix" }}
        # Source: APISIX native CRDs for Velero UI
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/kustomize/apisix
          kustomize:
            patches:
              - target:
                  kind: ApisixRoute
                  name: velero-ui
                patch: |
                  - op: replace
                    path: /spec/http/0/match/hosts/0
                    value: velero.{{ .common.domain }}
        {{- end }}
        {{- end }}

        {{- if .features.networkPolicy.ingressPolicy.enabled }}
        # Source: Velero UI ingress policy - conditional per Gateway provider
        {{- if eq .features.gatewayAPI.controller.provider "istio" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "cilium-dashboard-ingress-policy-istio.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "calico-dashboard-ingress-policy-istio.yaml"
          {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "apisix" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "cilium-dashboard-ingress-policy-apisix.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "calico-dashboard-ingress-policy-apisix.yaml"
          {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "traefik" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "cilium-dashboard-ingress-policy-traefik.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "calico-dashboard-ingress-policy-traefik.yaml"
          {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "nginx-gwf" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "cilium-dashboard-ingress-policy-nginx-gwf.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "calico-dashboard-ingress-policy-nginx-gwf.yaml"
          {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "envoy-gateway" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "cilium-dashboard-ingress-policy-envoy-gateway.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "calico-dashboard-ingress-policy-envoy-gateway.yaml"
          {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "cilium" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "cilium-dashboard-ingress-policy-cilium.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/velero/resources
          directory:
            include: "calico-dashboard-ingress-policy-cilium.yaml"
          {{- end }}
        {{- end }}
        {{- end }}

        # Source: Velero UI Helm Chart (OTWLD)
        - repoURL: https://helm.otwld.com/
          targetRevision: '{{ .velero.dashboard.version }}'
          chart: velero-ui
          helm:
            releaseName: velero-ui
            valuesObject:
              resources:
                requests:
                  cpu: '{{ .velero.dashboard.resources.requests.cpu }}'
                  memory: '{{ .velero.dashboard.resources.requests.memory }}'
                limits:
                  cpu: '{{ .velero.dashboard.resources.limits.cpu }}'
                  memory: '{{ .velero.dashboard.resources.limits.memory }}'

              # Velero API access
              configuration:
                general:
                  veleroNamespace: '{{ .velero.namespace }}'

              {{- if and .features.sso.enabled (eq .features.sso.provider "keycloak") }}
              # OIDC natif via Keycloak (pas de oauth2-proxy)
              env:
                - name: BASIC_AUTH_ENABLED
                  value: "false"
                - name: OAUTH_AUTH_ENABLED
                  value: "true"
                - name: OAUTH_NAME
                  value: "Keycloak"
                - name: OAUTH_CLIENT_ID
                  value: "velero-ui"
                - name: OAUTH_CLIENT_SECRET
                  valueFrom:
                    secretKeyRef:
                      name: velero-ui-oidc-credentials
                      key: client-secret
                - name: OAUTH_AUTHORIZATION_URL
                  value: "https://keycloak.{{ .common.domain }}/realms/k8s/protocol/openid-connect/auth"
                - name: OAUTH_TOKEN_URL
                  value: "https://keycloak.{{ .common.domain }}/realms/k8s/protocol/openid-connect/token"
                - name: OAUTH_USER_INFO_URL
                  value: "https://keycloak.{{ .common.domain }}/realms/k8s/protocol/openid-connect/userinfo"
                - name: OAUTH_OAUTH_SCOPE
                  value: "openid profile email groups"
                - name: OAUTH_GROUP_CLAIM
                  value: "groups"
                - name: OAUTH_REDIRECT_URI
                  value: "https://velero.{{ .common.domain }}/login"
                - name: NODE_EXTRA_CA_CERTS
                  value: "/etc/ssl/certs/custom-ca.crt"
              # Mount CA cert pour validation TLS vers Keycloak
              volumes:
                - name: ca-cert
                  secret:
                    secretName: root-ca
              volumeMounts:
                - name: ca-cert
                  mountPath: /etc/ssl/certs/custom-ca.crt
                  subPath: ca.crt
                  readOnly: true
              {{- end }}
        {{- end }}
