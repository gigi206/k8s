---
# =============================================================================
# Prometheus-Stack ApplicationSet (Monitoring)
# =============================================================================
# Déploie la stack complète de monitoring: Prometheus, Grafana, Alertmanager
# Docs: https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack
# =============================================================================

apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: prometheus-stack
  namespace: argo-cd
  annotations:
spec:
  goTemplate: true
  goTemplateOptions: ["missingkey=error"]

  generators:
    - merge:
        mergeKeys:
          - environment
        generators:
            # Config de base (valeurs par défaut)
          - git:
              repoURL: https://github.com/gigi206/k8s
              revision: 'HEAD'
              files:
                - path: deploy/argocd/config/config.yaml

            # Config spécifique à l'application
          - git:
              repoURL: https://github.com/gigi206/k8s
              revision: 'HEAD'
              files:
                - path: deploy/argocd/apps/prometheus-stack/config/*.yaml

  template:
    metadata:
      name: prometheus-stack
      namespace: argo-cd
      # labels:
      #   app: prometheus-stack
      #   environment: '{{ .environment }}'
      annotations:
    spec:
      project: default

      source:
        repoURL: https://prometheus-community.github.io/helm-charts
        targetRevision: '{{ .prometheusStack.version }}'
        chart: kube-prometheus-stack

      destination:
        server: https://kubernetes.default.svc
        namespace: monitoring

      syncPolicy:
        retry:
          limit: 10
          backoff:
            duration: 10s
            factor: 2
            maxDuration: 10m

  templatePatch: |
    spec:
      # Ignore default fields added by controllers (ExternalSecrets, Envoy Gateway)
      ignoreDifferences:
        - group: external-secrets.io
          kind: ExternalSecret
          jqPathExpressions:
            - .spec.data[].remoteRef.conversionStrategy
            - .spec.data[].remoteRef.decodingStrategy
            - .spec.data[].remoteRef.metadataPolicy
        - group: gateway.envoyproxy.io
          kind: SecurityPolicy
          jqPathExpressions:
            - .spec.oidc.clientSecret.group
            - .spec.oidc.clientSecret.kind
            - .spec.oidc.provider.backendRefs[].weight
            - .spec.oidc.refreshToken
      syncPolicy:
        syncOptions:
        {{- range .syncPolicy.syncOptions }}
          - {{ . }}
        {{- end }}
      {{- if .syncPolicy.automated.enabled }}
        automated:
          prune: {{ .syncPolicy.automated.prune }}
          selfHeal: {{ .syncPolicy.automated.selfHeal }}
      {{- end }}
      sources:
        {{- if .rke2.cis.enabled }}
        # Source: Namespace with PSA labels for CIS profile compatibility
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "namespace.yaml"
        {{- end }}
        {{- if .features.networkPolicy.defaultDenyPodIngress.enabled }}
          {{- if eq .cni.primary "cilium" }}
        # Source: Cilium internal ingress policy (pod-to-pod communication)
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "cilium-ingress-policy.yaml"
          {{- else if eq .cni.primary "calico" }}
        # Source: Calico internal ingress policy (pod-to-pod communication)
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "calico-ingress-policy.yaml"
          {{- end }}
        {{- end }}
        {{- if .features.networkPolicy.ingressPolicy.enabled }}
        # Source: Host ingress policy - conditional per Gateway provider
        {{- if eq .features.gatewayAPI.controller.provider "istio" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "cilium-ingress-policy-istio.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "calico-ingress-policy-istio.yaml"
          {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "apisix" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "cilium-ingress-policy-apisix.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "calico-ingress-policy-apisix.yaml"
          {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "traefik" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "cilium-ingress-policy-traefik.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "calico-ingress-policy-traefik.yaml"
          {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "nginx-gwf" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "cilium-ingress-policy-nginx-gwf.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "calico-ingress-policy-nginx-gwf.yaml"
          {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "envoy-gateway" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "cilium-ingress-policy-envoy-gateway.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "calico-ingress-policy-envoy-gateway.yaml"
          {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "cilium" }}
          {{- if eq .cni.primary "cilium" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "cilium-ingress-policy-cilium.yaml"
          {{- else if eq .cni.primary "calico" }}
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "calico-ingress-policy-cilium.yaml"
          {{- end }}
        {{- end }}
        {{- end }}
        {{- if .features.networkPolicy.egressPolicy.enabled }}
          {{- if eq .cni.primary "cilium" }}
        # Source: Cilium egress policy - allows Grafana to reach grafana.com and OIDC
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "cilium-egress-policy.yaml"
          {{- else if eq .cni.primary "calico" }}
        # Source: Calico egress policy - allows Grafana to reach grafana.com and OIDC
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "calico-egress-policy.yaml"
          {{- end }}
        {{- end }}
        {{- if .features.kubescape.enabled }}
        # Source: Kubescape exceptions for node-exporter privileged workloads
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "kubescape-exceptions.yaml"
        {{- end }}
        {{- if .features.kyverno.enabled }}
        # Source: Kyverno PolicyException (allows SA token mount for K8s API access)
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/resources
          directory:
            include: "kyverno-policy-exception.yaml"
        {{- end }}
        {{- if .features.gatewayAPI.enabled }}
        {{- if .features.gatewayAPI.httpRoute.enabled }}
        {{- if and .features.oauth2Proxy.enabled (eq .features.gatewayAPI.controller.provider "nginx-gwf") }}
        # Source: HTTPRoute + OAuth2 SnippetsFilter for nginx-gwf (atomic deployment)
        # SECURITY: HTTPRoutes and SnippetsFilter in same source = fail together if CRD missing
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/kustomize/httproute-oauth2-nginx-gwf
          kustomize:
            patches:
              - target:
                  kind: HTTPRoute
                  name: grafana
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: grafana.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: HTTPRoute
                  name: prometheus
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: prometheus.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: HTTPRoute
                  name: alertmanager
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: alertmanager.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: ReferenceGrant
                  name: gateway-monitoring-tls
                patch: |
                  - op: replace
                    path: /spec/from/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
        {{- else if and .features.oauth2Proxy.enabled (eq .features.gatewayAPI.controller.provider "istio") }}
        # Source: HTTPRoute + OAuth2 AuthorizationPolicy for Istio (atomic deployment)
        # SECURITY: HTTPRoutes and AuthorizationPolicy in same source = fail together if CRD missing
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/kustomize/httproute-oauth2-istio
          kustomize:
            patches:
              - target:
                  kind: HTTPRoute
                  name: grafana
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: grafana.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: HTTPRoute
                  name: prometheus
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: prometheus.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: HTTPRoute
                  name: alertmanager
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: alertmanager.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: ReferenceGrant
                  name: gateway-monitoring-tls
                patch: |
                  - op: replace
                    path: /spec/from/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: AuthorizationPolicy
                  name: oauth2-proxy-prometheus
                patch: |
                  - op: replace
                    path: /spec/rules/0/to/0/operation/hosts/0
                    value: prometheus.{{ .common.domain }}
              - target:
                  kind: AuthorizationPolicy
                  name: oauth2-proxy-alertmanager
                patch: |
                  - op: replace
                    path: /spec/rules/0/to/0/operation/hosts/0
                    value: alertmanager.{{ .common.domain }}
        {{- else if and .features.oauth2Proxy.enabled (eq .features.gatewayAPI.controller.provider "envoy-gateway") }}
        # Source: HTTPRoute + OAuth2 SecurityPolicy for Envoy Gateway (atomic deployment)
        # SECURITY: HTTPRoutes and SecurityPolicy in same source = fail together if CRD missing
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/kustomize/httproute-oauth2-envoy-gateway
          kustomize:
            patches:
              - target:
                  kind: HTTPRoute
                  name: grafana
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: grafana.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: HTTPRoute
                  name: prometheus
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: prometheus.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: HTTPRoute
                  name: alertmanager
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: alertmanager.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: ReferenceGrant
                  name: gateway-monitoring-tls
                patch: |
                  - op: replace
                    path: /spec/from/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  group: gateway.envoyproxy.io
                  kind: Backend
                  name: backend-keycloak
                patch: |
                  - op: replace
                    path: /spec/endpoints/0/fqdn/hostname
                    value: keycloak.{{ .common.domain }}
              - target:
                  group: gateway.envoyproxy.io
                  kind: SecurityPolicy
                  name: oidc-prometheus
                patch: |
                  - op: replace
                    path: /spec/oidc/provider/issuer
                    value: https://keycloak.{{ .common.domain }}/realms/k8s
                  - op: replace
                    path: /spec/oidc/provider/authorizationEndpoint
                    value: https://keycloak.{{ .common.domain }}/realms/k8s/protocol/openid-connect/auth
                  - op: replace
                    path: /spec/oidc/provider/tokenEndpoint
                    value: https://keycloak.{{ .common.domain }}/realms/k8s/protocol/openid-connect/token
                  - op: replace
                    path: /spec/oidc/redirectURL
                    value: https://prometheus.{{ .common.domain }}/oauth2/callback
              - target:
                  group: gateway.envoyproxy.io
                  kind: SecurityPolicy
                  name: oidc-alertmanager
                patch: |
                  - op: replace
                    path: /spec/oidc/provider/issuer
                    value: https://keycloak.{{ .common.domain }}/realms/k8s
                  - op: replace
                    path: /spec/oidc/provider/authorizationEndpoint
                    value: https://keycloak.{{ .common.domain }}/realms/k8s/protocol/openid-connect/auth
                  - op: replace
                    path: /spec/oidc/provider/tokenEndpoint
                    value: https://keycloak.{{ .common.domain }}/realms/k8s/protocol/openid-connect/token
                  - op: replace
                    path: /spec/oidc/redirectURL
                    value: https://alertmanager.{{ .common.domain }}/oauth2/callback
        {{- else }}
        # Source: HTTPRoute (Gateway API standard)
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/kustomize/httproute
          kustomize:
            patches:
              - target:
                  kind: HTTPRoute
                  name: grafana
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: grafana.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
              - target:
                  kind: HTTPRoute
                  name: prometheus
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: prometheus.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
                  {{- if and .features.oauth2Proxy.enabled (eq .features.gatewayAPI.controller.provider "traefik") }}
                  - op: add
                    path: /spec/rules/1/filters
                    value:
                      - type: ExtensionRef
                        extensionRef:
                          group: traefik.io
                          kind: Middleware
                          name: oauth2-proxy-auth
                  {{- end }}
                  {{- if and .features.oauth2Proxy.enabled (eq .features.gatewayAPI.controller.provider "cilium") }}
                  - op: replace
                    path: /spec/rules/1/backendRefs/0
                    value:
                      group: ""
                      kind: Service
                      name: oauth2-auth-proxy
                      namespace: oauth2-proxy
                      port: 8080
                      weight: 1
                  - op: add
                    path: /spec/rules/1/filters
                    value:
                      - type: RequestHeaderModifier
                        requestHeaderModifier:
                          set:
                            - name: X-Auth-Backend
                              value: "http://prometheus-stack-kube-prom-prometheus.monitoring.svc.cluster.local:9090"
                  {{- end }}
              - target:
                  kind: HTTPRoute
                  name: alertmanager
                patch: |
                  - op: replace
                    path: /spec/hostnames/0
                    value: alertmanager.{{ .common.domain }}
                  - op: replace
                    path: /spec/parentRefs/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
                  {{- if and .features.oauth2Proxy.enabled (eq .features.gatewayAPI.controller.provider "traefik") }}
                  - op: add
                    path: /spec/rules/1/filters
                    value:
                      - type: ExtensionRef
                        extensionRef:
                          group: traefik.io
                          kind: Middleware
                          name: oauth2-proxy-auth
                  {{- end }}
                  {{- if and .features.oauth2Proxy.enabled (eq .features.gatewayAPI.controller.provider "cilium") }}
                  - op: replace
                    path: /spec/rules/1/backendRefs/0
                    value:
                      group: ""
                      kind: Service
                      name: oauth2-auth-proxy
                      namespace: oauth2-proxy
                      port: 8080
                      weight: 1
                  - op: add
                    path: /spec/rules/1/filters
                    value:
                      - type: RequestHeaderModifier
                        requestHeaderModifier:
                          set:
                            - name: X-Auth-Backend
                              value: "http://prometheus-stack-kube-prom-alertmanager.monitoring.svc.cluster.local:9093"
                  {{- end }}
              - target:
                  kind: ReferenceGrant
                  name: gateway-monitoring-tls
                patch: |
                  - op: replace
                    path: /spec/from/0/namespace
                    value: '{{ .features.gatewayAPI.controller.gatewayNamespace }}'
        {{- end }}
        {{- else if eq .features.gatewayAPI.controller.provider "apisix" }}
        # Source: APISIX native CRDs (when HTTPRoute disabled and provider is apisix)
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/kustomize/apisix
          kustomize:
            patches:
              - target:
                  kind: ApisixRoute
                  name: grafana
                patch: |
                  - op: replace
                    path: /spec/http/0/match/hosts/0
                    value: grafana.{{ .common.domain }}
              - target:
                  kind: ApisixRoute
                  name: prometheus
                patch: |
                  - op: replace
                    path: /spec/http/0/match/hosts/0
                    value: prometheus.{{ .common.domain }}
                  - op: replace
                    path: /spec/http/1/match/hosts/0
                    value: prometheus.{{ .common.domain }}
              - target:
                  kind: ApisixRoute
                  name: alertmanager
                patch: |
                  - op: replace
                    path: /spec/http/0/match/hosts/0
                    value: alertmanager.{{ .common.domain }}
                  - op: replace
                    path: /spec/http/1/match/hosts/0
                    value: alertmanager.{{ .common.domain }}
        {{- end }}
        {{- end }}
        {{- if and .features.oauth2Proxy.enabled .features.gatewayAPI.httpRoute.enabled (eq .features.gatewayAPI.controller.provider "traefik") }}
        # Source: Traefik Middleware for OAuth2 Proxy forwardAuth
        # Note: Traefik has fail-close behavior - refuses routing if Middleware CRD missing
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/kustomize/oauth2-authz-traefik
        {{- end }}
        {{- if and .features.oauth2Proxy.enabled .features.gatewayAPI.httpRoute.enabled }}
        # Source: ReferenceGrant for oauth2-proxy cross-namespace HTTPRoute backend
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/kustomize/oauth2-authz
        {{- end }}
        {{- if .features.sso.enabled }}
        # Source: SSO generic resources (ClusterSecretStore, ExternalSecrets)
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/kustomize/sso
        {{- end }}
        {{- if and .features.sso.enabled (eq .features.sso.provider "keycloak") }}
        # Source: Keycloak-specific resources (Grafana client Job + OAuth2 Proxy URI registration)
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/kustomize/sso-keycloak
          kustomize:
            images:
              - 'curlimages/curl={{ .images.curl.repository }}:{{ .images.curl.tag }}'
            patches:
              - target:
                  kind: Job
                  name: grafana-keycloak-client
                patch: |
                  - op: replace
                    path: /spec/template/spec/containers/0/env/0/value
                    value: {{ .common.domain }}
              - target:
                  kind: Job
                  name: prometheus-stack-oauth2-proxy-uris
                patch: |
                  - op: replace
                    path: /spec/template/spec/containers/0/env/0/value
                    value: {{ .common.domain }}
        {{- end }}
        # Source: Encrypted secrets (KSOPS) - Grafana admin + OIDC credentials
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/secrets/{{ .environment }}
        {{- if .features.monitoring.enabled }}
        # Source: Prometheus health alerts (conditional) - with dynamic release label
        - repoURL: https://github.com/gigi206/k8s
          targetRevision: '{{ .git.revision }}'
          path: deploy/argocd/apps/prometheus-stack/kustomize/monitoring
          kustomize:
            commonLabels:
              release: '{{ .features.monitoring.release }}'
        {{- end }}
        # Source: Helm chart with dynamic parameters
        - repoURL: https://prometheus-community.github.io/helm-charts
          targetRevision: '{{ .prometheusStack.version }}'
          chart: kube-prometheus-stack
          helm:
            parameters:
            # Base parameters (must be here because templatePatch overwrites template)
            # Prometheus: retention and storage
            - name: prometheus.prometheusSpec.retention
              value: '{{ .prometheusStack.prometheus.retention | default "7d" }}'
            {{- if and .prometheusStack.prometheus.persistence.enabled .features.storage.enabled }}
            - name: prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage
              value: '{{ .prometheusStack.prometheus.persistence.size | default "5Gi" }}'
            - name: prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.accessModes[0]
              value: "ReadWriteOnce"
            {{- end }}

            # Grafana: admin credentials (from encrypted secret via KSOPS)
            - name: grafana.admin.existingSecret
              value: grafana-admin-credentials
            - name: grafana.admin.userKey
              value: admin-user
            - name: grafana.admin.passwordKey
              value: admin-password

            # Grafana: persistence
            - name: grafana.persistence.enabled
              value: '{{ and .prometheusStack.grafana.persistence.enabled .features.storage.enabled }}'
            {{- if and .prometheusStack.grafana.persistence.enabled .features.storage.enabled }}
            - name: grafana.persistence.size
              value: '{{ .prometheusStack.grafana.persistence.size | default "1Gi" }}'
            {{- end }}

            # Grafana: readiness probe
            - name: grafana.readinessProbe.timeoutSeconds
              value: '{{ .prometheusStack.grafana.readinessProbe.timeoutSeconds | default "5" }}'

            # Grafana: sidecar dashboards
            - name: grafana.sidecar.dashboards.enabled
              value: '{{ .prometheusStack.grafana.sidecar.dashboards.enabled | default "true" }}'
            - name: grafana.sidecar.dashboards.folderAnnotation
              value: '{{ .features.monitoring.dashboard.folderAnnotation }}'
            - name: grafana.sidecar.dashboards.annotations.grafana_dashboard_folder
              value: '{{ .features.monitoring.dashboard.baseFolder }}/{{ .prometheusStack.grafana.sidecar.dashboards.folder }}'
            - name: grafana.sidecar.dashboards.provider.foldersFromFilesStructure
              value: '{{ .prometheusStack.grafana.sidecar.dashboards.provider.foldersFromFilesStructure | default "true" }}'

            # Grafana: ServiceMonitor
            - name: grafana.serviceMonitor.enabled
              value: '{{ .prometheusStack.grafana.serviceMonitor.enabled | default "true" }}'
            - name: grafana.serviceMonitor.labels.release
              value: '{{ .features.monitoring.release }}'

            # Alertmanager
            - name: alertmanager.enabled
              value: '{{ .prometheusStack.alertmanager.enabled | default "false" }}'

            # Node Exporter: disable non-Linux dashboards
            - name: nodeExporter.operatingSystems.linux.enabled
              value: "true"
            - name: nodeExporter.operatingSystems.darwin.enabled
              value: "false"
            - name: nodeExporter.operatingSystems.aix.enabled
              value: "false"

            # Kube-proxy: disable (Cilium replaces kube-proxy)
            - name: kubeProxy.enabled
              value: "false"

            # Prometheus Operator: use cert-manager for admission webhooks
            - name: prometheusOperator.admissionWebhooks.certManager.enabled
              value: "true"
            - name: prometheusOperator.admissionWebhooks.certManager.admissionCert.duration
              value: "8760h"

            # Prometheus Operator: resources
            {{- if .prometheusStack.prometheusOperator.resources }}
            - name: prometheusOperator.resources.requests.cpu
              value: '{{ .prometheusStack.prometheusOperator.resources.requests.cpu }}'
            - name: prometheusOperator.resources.requests.memory
              value: '{{ .prometheusStack.prometheusOperator.resources.requests.memory }}'
            - name: prometheusOperator.resources.limits.cpu
              value: '{{ .prometheusStack.prometheusOperator.resources.limits.cpu }}'
            - name: prometheusOperator.resources.limits.memory
              value: '{{ .prometheusStack.prometheusOperator.resources.limits.memory }}'
            {{- end }}

            # Kube State Metrics: resources
            {{- if .prometheusStack.kubeStateMetrics.resources }}
            - name: kube-state-metrics.resources.requests.cpu
              value: '{{ .prometheusStack.kubeStateMetrics.resources.requests.cpu }}'
            - name: kube-state-metrics.resources.requests.memory
              value: '{{ .prometheusStack.kubeStateMetrics.resources.requests.memory }}'
            - name: kube-state-metrics.resources.limits.cpu
              value: '{{ .prometheusStack.kubeStateMetrics.resources.limits.cpu }}'
            - name: kube-state-metrics.resources.limits.memory
              value: '{{ .prometheusStack.kubeStateMetrics.resources.limits.memory }}'
            {{- end }}

            # Prometheus: replicas and resources
            {{- if .prometheusStack.prometheus.replicas }}
            - name: prometheus.prometheusSpec.replicas
              value: "{{ .prometheusStack.prometheus.replicas }}"
            {{- end }}
            {{- if .prometheusStack.prometheus.resources }}
            - name: prometheus.prometheusSpec.resources.requests.cpu
              value: '{{ .prometheusStack.prometheus.resources.requests.cpu }}'
            - name: prometheus.prometheusSpec.resources.requests.memory
              value: '{{ .prometheusStack.prometheus.resources.requests.memory }}'
            - name: prometheus.prometheusSpec.resources.limits.cpu
              value: '{{ .prometheusStack.prometheus.resources.limits.cpu }}'
            - name: prometheus.prometheusSpec.resources.limits.memory
              value: '{{ .prometheusStack.prometheus.resources.limits.memory }}'
            {{- end }}

            # Prometheus: remote write receiver
            {{- if .prometheusStack.prometheus.enableRemoteWriteReceiver }}
            - name: prometheus.prometheusSpec.enableRemoteWriteReceiver
              value: '{{ .prometheusStack.prometheus.enableRemoteWriteReceiver }}'
            {{- end }}

            # Prometheus: ingress
            {{- if .prometheusStack.prometheus.ingress }}
            {{- if .prometheusStack.prometheus.ingress.enabled }}
            - name: prometheus.ingress.enabled
              value: "true"
            - name: prometheus.ingress.ingressClassName
              value: '{{ .features.ingress.class }}'
            - name: prometheus.ingress.hosts[0]
              value: 'prometheus.{{ .common.domain }}'
            {{- if .features.certManager.enabled }}
            - name: prometheus.ingress.annotations.cert-manager\.io/cluster-issuer
              value: '{{ .common.clusterIssuer }}'
            - name: prometheus.ingress.tls[0].secretName
              value: prometheus-cert-tls
            - name: prometheus.ingress.tls[0].hosts[0]
              value: 'prometheus.{{ .common.domain }}'
            {{- end }}
            {{- end }}
            {{- end }}

            # Grafana: replicas and resources
            {{- if .prometheusStack.grafana.replicas }}
            - name: grafana.replicas
              value: "{{ .prometheusStack.grafana.replicas }}"
            {{- end }}
            {{- if .prometheusStack.grafana.resources }}
            - name: grafana.resources.requests.cpu
              value: '{{ .prometheusStack.grafana.resources.requests.cpu }}'
            - name: grafana.resources.requests.memory
              value: '{{ .prometheusStack.grafana.resources.requests.memory }}'
            - name: grafana.resources.limits.cpu
              value: '{{ .prometheusStack.grafana.resources.limits.cpu }}'
            - name: grafana.resources.limits.memory
              value: '{{ .prometheusStack.grafana.resources.limits.memory }}'
            {{- end }}

            # Grafana: ingress
            {{- if .prometheusStack.grafana.ingress }}
            {{- if .prometheusStack.grafana.ingress.enabled }}
            - name: grafana.ingress.enabled
              value: "true"
            - name: grafana.ingress.ingressClassName
              value: '{{ .features.ingress.class }}'
            - name: grafana.ingress.hosts[0]
              value: 'grafana.{{ .common.domain }}'
            {{- if .features.certManager.enabled }}
            - name: grafana.ingress.annotations.cert-manager\.io/cluster-issuer
              value: '{{ .common.clusterIssuer }}'
            - name: grafana.ingress.tls[0].secretName
              value: grafana-cert-tls
            - name: grafana.ingress.tls[0].hosts[0]
              value: 'grafana.{{ .common.domain }}'
            {{- end }}
            {{- end }}
            {{- end }}

            # Alertmanager: enabled and replicas
            {{- if .prometheusStack.alertmanager.enabled }}
            - name: alertmanager.alertmanagerSpec.replicas
              value: '{{ .prometheusStack.alertmanager.replicas | default "1" }}'

            # Alertmanager: ingress
            {{- if .prometheusStack.alertmanager.ingress }}
            {{- if .prometheusStack.alertmanager.ingress.enabled }}
            - name: alertmanager.ingress.enabled
              value: "true"
            - name: alertmanager.ingress.ingressClassName
              value: '{{ .features.ingress.class }}'
            - name: alertmanager.ingress.hosts[0]
              value: 'alertmanager.{{ .common.domain }}'
            {{- if .features.certManager.enabled }}
            - name: alertmanager.ingress.annotations.cert-manager\.io/cluster-issuer
              value: '{{ .common.clusterIssuer }}'
            - name: alertmanager.ingress.tls[0].secretName
              value: alertmanager-cert-tls
            - name: alertmanager.ingress.tls[0].hosts[0]
              value: 'alertmanager.{{ .common.domain }}'
            {{- end }}
            {{- end }}

            # Alertmanager: resources
            {{- if .prometheusStack.alertmanager.resources }}
            - name: alertmanager.alertmanagerSpec.resources.requests.cpu
              value: '{{ .prometheusStack.alertmanager.resources.requests.cpu }}'
            - name: alertmanager.alertmanagerSpec.resources.requests.memory
              value: '{{ .prometheusStack.alertmanager.resources.requests.memory }}'
            - name: alertmanager.alertmanagerSpec.resources.limits.cpu
              value: '{{ .prometheusStack.alertmanager.resources.limits.cpu }}'
            - name: alertmanager.alertmanagerSpec.resources.limits.memory
              value: '{{ .prometheusStack.alertmanager.resources.limits.memory }}'
            {{- end }}

            # Alertmanager: storage
            {{- if and .prometheusStack.alertmanager.persistence.enabled .features.storage.enabled }}
            - name: alertmanager.alertmanagerSpec.storage.volumeClaimTemplate.spec.resources.requests.storage
              value: '{{ .prometheusStack.alertmanager.persistence.size }}'
            {{- end }}
            {{- end }}
            {{- end }}

            # Prometheus Pushgateway
            - name: prometheus-pushgateway.enabled
              value: '{{ .prometheusStack.pushgateway.enabled }}'
            {{- if .prometheusStack.pushgateway.enabled }}
            {{- if .prometheusStack.pushgateway.resources }}
            - name: prometheus-pushgateway.resources.requests.cpu
              value: '{{ .prometheusStack.pushgateway.resources.requests.cpu }}'
            - name: prometheus-pushgateway.resources.requests.memory
              value: '{{ .prometheusStack.pushgateway.resources.requests.memory }}'
            - name: prometheus-pushgateway.resources.limits.cpu
              value: '{{ .prometheusStack.pushgateway.resources.limits.cpu }}'
            - name: prometheus-pushgateway.resources.limits.memory
              value: '{{ .prometheusStack.pushgateway.resources.limits.memory }}'
            {{- end }}
            {{- if .prometheusStack.pushgateway.serviceMonitor }}
            - name: prometheus-pushgateway.serviceMonitor.enabled
              value: '{{ .prometheusStack.pushgateway.serviceMonitor.enabled }}'
            - name: prometheus-pushgateway.serviceMonitor.namespace
              value: '{{ .prometheusStack.pushgateway.serviceMonitor.namespace }}'
            {{- end }}
            {{- end }}

            # Node Exporter: resources
            {{- if .prometheusStack.nodeExporter }}
            {{- if .prometheusStack.nodeExporter.resources }}
            - name: prometheus-node-exporter.resources.requests.cpu
              value: '{{ .prometheusStack.nodeExporter.resources.requests.cpu }}'
            - name: prometheus-node-exporter.resources.requests.memory
              value: '{{ .prometheusStack.nodeExporter.resources.requests.memory }}'
            - name: prometheus-node-exporter.resources.limits.cpu
              value: '{{ .prometheusStack.nodeExporter.resources.limits.cpu }}'
            - name: prometheus-node-exporter.resources.limits.memory
              value: '{{ .prometheusStack.nodeExporter.resources.limits.memory }}'
            {{- end }}
            {{- end }}

            # Grafana: grafana.ini configuration (via valuesObject pour structure imbriquée)
            # Note: Grafana 12+ a supprimé Legacy Alerting, seul unified_alerting est disponible
            # OIDC is enabled only if both SSO feature flag AND per-app oidc.enabled are true
            {{- $oidcEnabled := and .features.sso.enabled .prometheusStack.grafana.oidc .prometheusStack.grafana.oidc.enabled }}
            valuesObject:
              # Prometheus config-reloader resources
              {{- if .prometheusStack.prometheusOperator.configReloader }}
              {{- if .prometheusStack.prometheusOperator.configReloader.resources }}
              prometheusOperator:
                prometheusConfigReloader:
                  resources:
                    requests:
                      cpu: '{{ .prometheusStack.prometheusOperator.configReloader.resources.requests.cpu }}'
                      memory: '{{ .prometheusStack.prometheusOperator.configReloader.resources.requests.memory }}'
                    limits:
                      cpu: '{{ .prometheusStack.prometheusOperator.configReloader.resources.limits.cpu }}'
                      memory: '{{ .prometheusStack.prometheusOperator.configReloader.resources.limits.memory }}'
              {{- end }}
              {{- end }}

              grafana:
                # Grafana sidecar resources
                {{- if .prometheusStack.grafana.sidecar.resources }}
                sidecar:
                  resources:
                    requests:
                      cpu: '{{ .prometheusStack.grafana.sidecar.resources.requests.cpu }}'
                      memory: '{{ .prometheusStack.grafana.sidecar.resources.requests.memory }}'
                    limits:
                      cpu: '{{ .prometheusStack.grafana.sidecar.resources.limits.cpu }}'
                      memory: '{{ .prometheusStack.grafana.sidecar.resources.limits.memory }}'
                {{- end }}
                # PSA restricted compatibility
                podSecurityContext:
                  runAsNonRoot: true
                  runAsUser: 472
                  runAsGroup: 472
                  fsGroup: 472
                  seccompProfile:
                    type: RuntimeDefault
                containerSecurityContext:
                  allowPrivilegeEscalation: false
                  capabilities:
                    drop: ["ALL"]
                  readOnlyRootFilesystem: false
                # Disable init container running as root
                initChownData:
                  enabled: false
                {{- if $oidcEnabled }}
                # Mount OIDC client secret and CA certificate as files
                extraSecretMounts:
                  - name: oidc-client-secret
                    secretName: grafana-oidc-client-secret
                    mountPath: /etc/secrets/oidc
                    readOnly: true
                  - name: root-ca
                    secretName: root-ca
                    mountPath: /etc/ssl/certs/root-ca
                    readOnly: true
                {{- end }}
                grafana.ini:
                  server:
                    root_url: https://grafana.{{ .common.domain }}
                  analytics:
                    check_for_updates: {{ .prometheusStack.grafana.grafanaIni.analytics.check_for_updates | default false }}
                  unified_alerting:
                    enabled: {{ .prometheusStack.grafana.grafanaIni.unified_alerting.enabled | default true }}
                  auth.anonymous:
                    enabled: false
                  {{- if $oidcEnabled }}
                  # OIDC/OAuth2 configuration (Keycloak)
                  # URLs construites dynamiquement avec common.domain
                  auth.generic_oauth:
                    enabled: true
                    name: "{{ .prometheusStack.grafana.oidc.name }}"
                    allow_sign_up: {{ .prometheusStack.grafana.oidc.allowSignUp }}
                    auto_login: {{ .prometheusStack.grafana.oidc.autoLogin | default false }}
                    client_id: "{{ .prometheusStack.grafana.oidc.clientId }}"
                    client_secret: $__file{/etc/secrets/oidc/client-secret}
                    scopes: "{{ .prometheusStack.grafana.oidc.scopes }}"
                    auth_url: "https://keycloak.{{ .common.domain }}/realms/{{ .prometheusStack.grafana.oidc.realm }}/protocol/openid-connect/auth"
                    token_url: "https://keycloak.{{ .common.domain }}/realms/{{ .prometheusStack.grafana.oidc.realm }}/protocol/openid-connect/token"
                    api_url: "https://keycloak.{{ .common.domain }}/realms/{{ .prometheusStack.grafana.oidc.realm }}/protocol/openid-connect/userinfo"
                    role_attribute_path: "{{ .prometheusStack.grafana.oidc.roleAttributePath }}"
                    allow_assign_grafana_admin: {{ .prometheusStack.grafana.oidc.allowAssignGrafanaAdmin | default false }}
                    signout_redirect_url: "https://keycloak.{{ .common.domain }}/realms/{{ .prometheusStack.grafana.oidc.realm }}/protocol/openid-connect/logout?id_token_hint=${id_token}&post_logout_redirect_uri=https%3A%2F%2Fgrafana.{{ .common.domain }}%2Flogin"
                    tls_client_ca: /etc/ssl/certs/root-ca/ca.crt
                  {{- end }}
                {{- $lokiEnabled := and .features.logging.enabled .features.logging.loki.enabled }}
                {{- $jaegerEnabled := and .features.tracing.enabled (eq .features.tracing.provider "jaeger") }}
                {{- $tempoEnabled := and .features.tracing.enabled (eq .features.tracing.provider "tempo") }}
                {{- if or $lokiEnabled $jaegerEnabled $tempoEnabled }}
                # Additional datasources (Loki, Jaeger, Tempo)
                additionalDataSources:
                  {{- if $lokiEnabled }}
                  # Loki datasource for log querying
                  - name: Loki
                    type: loki
                    uid: loki
                    url: http://loki.loki.svc.cluster.local:3100
                    access: proxy
                    isDefault: false
                    jsonData:
                      maxLines: 1000
                      {{- if $tempoEnabled }}
                      # Derived fields for trace correlation (Tempo)
                      # Supports: trace_id=xxx, Traceparent:[00-xxx-...], X-B3-Traceid:[xxx]
                      derivedFields:
                        - name: TraceID
                          matcherRegex: '(?:(?:trace_id|traceId|traceid)[=":\s]+|Traceparent:\[00-|X-B3-Traceid:\[)([a-f0-9]{16,32})'
                          url: "$${__value.raw}"
                          datasourceUid: tempo
                          urlDisplayLabel: "View Trace"
                      {{- else if $jaegerEnabled }}
                      # Derived fields for trace correlation (Jaeger)
                      derivedFields:
                        - name: TraceID
                          matcherRegex: '"trace_id":"([a-f0-9]+)"'
                          url: "$${__value.raw}"
                          datasourceUid: jaeger
                      {{- end }}
                  {{- end }}
                  {{- if $tempoEnabled }}
                  # Tempo datasource for distributed tracing
                  - name: Tempo
                    type: tempo
                    uid: tempo
                    url: http://tempo.tempo.svc.cluster.local:3100
                    access: proxy
                    isDefault: false
                    jsonData:
                      {{- if $lokiEnabled }}
                      tracesToLogsV2:
                        datasourceUid: loki
                        spanStartTimeShift: '-1h'
                        spanEndTimeShift: '1h'
                        filterByTraceID: true
                        filterBySpanID: true
                        customQuery: true
                        query: '{namespace="$${__span.tags["namespace"]}"} | json | trace_id=`$${__trace.traceId}`'
                      {{- end }}
                      tracesToMetrics:
                        datasourceUid: prometheus
                        spanStartTimeShift: '-1h'
                        spanEndTimeShift: '1h'
                      nodeGraph:
                        enabled: true
                      serviceMap:
                        datasourceUid: prometheus
                  {{- end }}
                  {{- if $jaegerEnabled }}
                  # Jaeger datasource for distributed tracing
                  - name: Jaeger
                    type: jaeger
                    uid: jaeger
                    url: http://jaeger-query.jaeger.svc.cluster.local:16686
                    access: proxy
                    isDefault: false
                    jsonData:
                      {{- if $lokiEnabled }}
                      tracesToLogsV2:
                        datasourceUid: loki
                        spanStartTimeShift: '-1h'
                        spanEndTimeShift: '1h'
                        filterByTraceID: true
                        filterBySpanID: true
                      {{- end }}
                      tracesToMetrics:
                        datasourceUid: prometheus
                        spanStartTimeShift: '-1h'
                        spanEndTimeShift: '1h'
                      nodeGraph:
                        enabled: true
                  {{- end }}
                {{- end }}
